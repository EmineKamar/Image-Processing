{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('../input/sarscov2-ctscan-dataset'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from builtins import range, input\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten, AveragePooling2D, Dropout\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix, roc_curve\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom glob import glob\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nfrom tensorflow.keras.utils import to_categorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncovid_path = '../input/sarscov2-ctscan-dataset/COVID'\nnoncovid_path = '../input/sarscov2-ctscan-dataset/non-COVID'\ncovid_files = glob(covid_path + '/*')\nnoncovid_files = glob(noncovid_path + '/*')\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"First 5 Covid Files: \",covid_files[0:5])\nprint(\"Total Count: \",len(covid_files))\nprint(\"First 5 NonCovid Files: \",noncovid_files[0:5])\nprint(\"Total Count: \",len(noncovid_files))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"covid_labels = []\nnoncovid_labels = []\n\ncovid_images=[]\nnoncovid_images=[]\n\nfor i in range(len(covid_files)):\n  image = cv2.imread(covid_files[i]) # read file \n  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # arrange format as per keras\n  image = cv2.resize(image,(224,224)) # resize as per model\n  covid_images.append(image) # append image\n  covid_labels.append('CT_COVID') #append class label\nfor i in range(len(noncovid_files)):\n  image = cv2.imread(noncovid_files[i])\n  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n  image = cv2.resize(image,(224,224))\n  noncovid_images.append(image)\n  noncovid_labels.append('CT_NonCOVID')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images(images, title):\n    nrows, ncols = 5, 8\n    figsize = [10, 6]\n\n    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, facecolor=(1, 1, 1))\n\n    for i, axi in enumerate(ax.flat):\n        axi.imshow(images[i])\n        axi.set_axis_off()\n\n    plt.suptitle(title, fontsize=24)\n    plt.tight_layout(pad=0.2, rect=[0, 0, 1, 0.9])\n    plt.show()\nplot_images(covid_images, 'Positive COVID-19 CT Scan')\nplot_images(noncovid_images, 'Negative COVID-19 CT Scan')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"covid_images = np.array(covid_images) / 255\nnoncovid_images = np.array(noncovid_images) / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"covid_x_train, covid_x_test, covid_y_train, covid_y_test = train_test_split(\n    covid_images, covid_labels, test_size=0.2)\nnoncovid_x_train, noncovid_x_test, noncovid_y_train, noncovid_y_test = train_test_split(\n    noncovid_images, noncovid_labels, test_size=0.2)\n\nX_train = np.concatenate((noncovid_x_train, covid_x_train), axis=0)\nX_test = np.concatenate((noncovid_x_test, covid_x_test), axis=0)\ny_train = np.concatenate((noncovid_y_train, covid_y_train), axis=0)\ny_test = np.concatenate((noncovid_y_test, covid_y_test), axis=0)\n\ny_train = LabelBinarizer().fit_transform(y_train)\ny_train = to_categorical(y_train)\n\ny_test = LabelBinarizer().fit_transform(y_test)\ny_test = to_categorical(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(covid_x_train, 'X_train')\nplot_images(covid_x_test, 'X_test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\ndef get_model(width=128, height=128, depth=64):\n    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n\n    inputs = keras.Input((width, height, depth, 1))\n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.GlobalAveragePooling3D()(x)\n    x = layers.Dense(units=512, activation=\"relu\")(x)\n    x = layers.Dropout(0.3)(x)\n\n    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n    \n    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model(width=128, height=128, depth=64)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\nImage(filename='convnet.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport cv2\nimport os\nfrom tqdm import tqdm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Model,Sequential, Input, load_model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model(width=128, height=128, depth=64)\nannealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.70, patience=5, verbose=1, min_lr=1e-4)\ncheckpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n\ndatagen= ImageDataGenerator(rotation_range=360, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2, horizontal_flip=True, vertical_flip=True)\ndatagen.fit(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import adam_v2\noptimizer = adam_v2.Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model(width=128, height=128, depth=64)\nannealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.70, patience=5, verbose=1, min_lr=1e-4)\ncheckpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n\ndatagen = ImageDataGenerator(rotation_range=360,\n                        width_shift_range=0.2, \n                        height_shift_range=0.2, \n                        zoom_range=0.2, \n                        horizontal_flip=True, \n                        vertical_flip=True) \n\ndatagen.fit(X_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nIMAGE_SIZE = [224, 224]\nepochs = 500\nbatch_size = 32\nhist = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n               steps_per_epoch=X_train.shape[0] // batch_size,\n               epochs=epochs,\n               verbose=1,\n               callbacks=[annealer, checkpoint],\n               validation_data=(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}